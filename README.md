# Elastic Stack for Raspberry Pi

## Background
I wanted to be able to run a complete Elastic Stack on a Raspberry Pi (Low power) to act as a SIEM as well monitor my network. Elasticsearch itself has a build for Arm64 however Kibana did not, however after a little playing around I was able to get it to successfully run as a containter as well as installed from a package. [My repo for this Kibana Arm can be found here](https://github.com/jamesgarside/kibana-arm).
I chose to deploy the Elastic Stack on Docker because that way I could take advantage of easy deployment to multiple nodes by utilising Docker Swarm. This will also run on a single node using Docker-Compose (TBC).

## Requirements
- Raspberry Pi 4 (4GB+)
- Docker Compose or Docker Swarm

## Usage

### Docker Swarm
This will deploy a three node Elasticsearch Cluster with Kibana instance.
1. Ensure Docker Swarm has been initialised and the other nodes have been added if using a cluster.
    1. Run `docker swarm init` to initialise the Swarm
    2. Copy the output from `docker swarm join-token manager` run it on the other nodes to be joined to the Swarm.

2. Clone this repo to one of the Swarm Master nodes using `git clone https://github.com/jamesgarside/elastic-stack-arm.git`.
3. Change directory into the cloned repo `cd elastic-stack-arm`
4. Edit the deployment constraint hostnames for each service within `docker-compose-swarm.default.yml` file to the hostnames of your cluster nodes. This ensures one Elasticsearch node runs on each Swarm node as well as ensures that persistant data is accessed by the correct Docker Service. 
5. Edit the Environment Vars within the `.env` file to your desired settings.
6. Run the build stack script `./build-stack.sh`
    This script does a few things:
    1. Sets Environment Variables from the within the .env file.
    2. Generates crypt for the Elastic Stack nodes
    3. Stores the crypt in Docker Secrets (Makes it available to all docker nodes as well as protects it)
    4. Deploys the Elastic Stack to the Swam using the inital config
    5. Generate the Elasticsearch passwords using Elasticsearches password init binary. These get stored in a file call `stack-passwords.txt`
    6. Creates a new `docker-compose.yml` with updated values unique to the deployment.
        - Sets the kibana_system password which was generated in step 5. 
        - Sets the cluster name based on the value in `.env`.
        - Sets a unique string for the Kibana SavedObjects encryption string. 
    7. Re-deploys/Updates the stack with the new docker-compose. 
7. Once the script has finished the stack is complete. Give Kibana a few minute to start up as it requires the Elasticsearch cluster to have started before it can initialise itself. 
8. To log in use the Elastic user generated by the `build-stack.sh` script which is stored in the `stack-passwords.txt` file.

### Docker-Compose
To be completed. An early version of the Docker-Compose file is located within the `resources` folder. Crypt will need to be manually generated by using the `gen-certs.sh` script located in the gen_certs folder.

## Further Config
Further configuration can be carried out by using either Environment variables specified within the Service section of the Docker-Compose file or by bind mounting a Config file within the container. 
